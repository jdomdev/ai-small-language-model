{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jdomdev/ai-small-language-model/blob/feature%2Fimdb-sentiment/train_sentiment_colab_full_data_cleaned.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4f1eafad",
      "metadata": {
        "id": "4f1eafad"
      },
      "source": [
        "El modelo actual pesa 257MB, lo que confirma que la división será necesaria para subirlo a GitHub."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "289eab4f",
      "metadata": {
        "id": "289eab4f"
      },
      "source": [
        "Vamos a crear el notebook de Colab paso a paso, conectarlo con el repositorio de GitHub propio (**jdomdev/ai-small-language-model**) y entrenar el modelo DistilBERT en la nube de Google(Colab) con todos los registros los datasets (train: 25.000 / test: 25.000)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8166026d",
      "metadata": {
        "id": "8166026d",
        "lines_to_next_cell": 2
      },
      "source": [
        "Contenido del Notebook de Colab (train_sentiment_colab_full_data.ipynb)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "wIRFMgJy7SWu",
      "metadata": {
        "id": "wIRFMgJy7SWu"
      },
      "source": [
        "  **Error en TrainingArguments()**\n",
        "\n",
        "\n",
        "  El mensaje de error nos da la pista clave:\n",
        "  sentence-transformers 4.1.0 requires transformers<5.0.0,>=4.41.0, but you have transformers 4.38.2 which is incompatible.\n",
        "\n",
        "  Esto significa que tu Colab tiene sentence-transformers instalado, y esta librería necesita una versión de transformers que sea\n",
        "  4.41.0 o más nueva. La que yo te sugerí (4.38.2) es demasiado vieja para tu entorno actual.\n",
        "\n",
        "  La Solución Definitiva\n",
        "\n",
        "  Vamos a corregirlo. En lugar de forzar una versión específica, simplemente pediremos la última versión estable. pip es lo\n",
        "  suficientemente inteligente como para encontrar un conjunto de versiones que funcionen entre sí.\n",
        "\n",
        "  Reemplaza la celda de instalación que te di antes por esta nueva celda:\n",
        "\n",
        "    1 # Paso 1: Instalar las versiones más recientes y compatibles de las librerías\n",
        "    2 # Usamos --upgrade para asegurarnos de que tenemos las últimas versiones que no entren en conflicto.\n",
        "    3 print(\"Instalando las últimas versiones de transformers, datasets y accelerate...\")\n",
        "    4 !pip install --upgrade -q transformers datasets accelerate\n",
        "    5\n",
        "    6 # Paso 2: Forzar el reinicio del entorno para que Colab use las nuevas librerías\n",
        "    7 # La sesión se reiniciará. Esto es normal y esperado.\n",
        "    8 import os\n",
        "    9 print(\"Instalación completa. Reiniciando el entorno de ejecución...\")\n",
        "   10 os.kill(os.getpid(), 9)\n",
        "\n",
        "  ¿Qué hace este nuevo código?\n",
        "\n",
        "   1. `!pip install --upgrade -q transformers datasets accelerate`:\n",
        "       * --upgrade: Le dice a pip que instale la versión más reciente disponible que sea compatible con el resto del entorno.\n",
        "       * Ya no fijamos versiones (==X.Y.Z), lo que le da a pip la libertad de resolver los conflictos que vimos antes.\n",
        "       * -q: Es solo para que la salida de la instalación sea más limpia (modo \"quiet\").\n",
        "\n",
        "   2. `os.kill(...)`: Mantenemos este comando porque es la forma más segura de garantizar que el entorno se reinicia y carga las\n",
        "      librerías que acabamos de instalar.\n",
        "\n",
        "  Pasos a seguir\n",
        "\n",
        "   1. Elimina o reemplaza la celda de instalación anterior con el nuevo código que te he puesto arriba.\n",
        "   2. Ejecuta esta nueva celda.\n",
        "   3. Verás los mensajes de instalación y luego el aviso de que la sesión se ha reiniciado (\"session crashed\"). Esto es correcto.\n",
        "   4. Ahora, ejecuta el resto de las celdas de tu notebook en orden.\n",
        "\n",
        "  Ahora, al ejecutar el resto de tu código, el TypeError original sobre evaluation_strategy debería estar resuelto\n",
        "  definitivamente, ya que tendrás una versión de transformers reciente y compatible con todo tu entorno de Colab."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "VBxngSSc48Qo",
      "metadata": {
        "id": "VBxngSSc48Qo"
      },
      "outputs": [],
      "source": [
        "# Paso 1: Instalar las versiones más recientes y compatibles de las librerías\n",
        "# Usamos --upgrade para asegurarnos de que tenemos las últimas versiones que no entren en conflicto.\n",
        "\n",
        "print(\"Instalando las últimas versiones de transformers, datasets y accelerate...\")\n",
        "!pip install --upgrade -q transformers datasets accelerate evaluate\n",
        "\n",
        "# Paso 2: Forzar el reinicio del entorno para que Colab use las nuevas librerías\n",
        "# La sesión se reiniciará. Esto es normal y esperado.\n",
        "import os\n",
        "print(\"Instalación completa. Reiniciando el entorno de ejecución...\")\n",
        "os.kill(os.getpid(), 9)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "knk9Kd1VzL5J",
      "metadata": {
        "id": "knk9Kd1VzL5J"
      },
      "outputs": [],
      "source": [
        "#!pip install --upgrade transformers datasets"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "89068404",
      "metadata": {
        "id": "89068404"
      },
      "source": [
        "## **Bloque 1: Configuración Inicial e Importaciones**"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "18f5e8e7",
      "metadata": {
        "id": "18f5e8e7"
      },
      "source": [
        "Este bloque se encarga de instalar las librerías necesarias (aunque muchas ya están en Colab, es buena práctica incluirlas para\n",
        "asegurar la reproducibilidad), montar Google Drive y definir las rutas."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "386b97e9",
      "metadata": {
        "id": "386b97e9"
      },
      "outputs": [],
      "source": [
        "# Instalar o actualizar librerías necesarias (muchas ya están en Colab, pero es buena práctica)\n",
        "#!pip install --upgrade transformers[torch] datasets evaluate scikit-learn accelerate pandas numpy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "118b72fd",
      "metadata": {
        "id": "118b72fd"
      },
      "outputs": [],
      "source": [
        "# Importar librerías\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from datasets import load_dataset, Dataset\n",
        "from evaluate import load\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification, TrainingArguments, Trainer\n",
        "import torch\n",
        "from sklearn.model_selection import train_test_split\n",
        "import re\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6be50285",
      "metadata": {
        "id": "6be50285",
        "outputId": "5178653b-bada-4a75-efcb-86630a58379a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "# Montar Google Drive para guardar/cargar archivos grandes\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fc54a1ed",
      "metadata": {
        "id": "fc54a1ed"
      },
      "outputs": [],
      "source": [
        "# Definir la ruta base en Google Drive para guardar los resultados y el modelo\n",
        "# Asegúrate de que esta carpeta exista en tu Google Drive\n",
        "DRIVE_BASE_PATH = \"/content/drive/My Drive/Colab Notebooks/mod03-projs/ai-small-language-model/\"\n",
        "os.makedirs(DRIVE_BASE_PATH, exist_ok=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ca588b43",
      "metadata": {
        "id": "ca588b43",
        "outputId": "973b1567-88d3-4455-d199-0451519dc148"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Configuración inicial completada.\n"
          ]
        }
      ],
      "source": [
        "print(\"Configuración inicial completada.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2340ee00",
      "metadata": {
        "id": "2340ee00"
      },
      "source": [
        "## **Bloque 2: Carga y Guardado de Datasets Originales a CSV**"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2cf37230",
      "metadata": {
        "id": "2cf37230"
      },
      "source": [
        "Aquí cargaremos los datasets completos de IMDb y los guardaremos como CSVs separados en tu Google Drive."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dWKuuicQZzFZ",
      "metadata": {
        "id": "dWKuuicQZzFZ"
      },
      "source": [
        "Cargamos el Hugging Face Token(HF_Token)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a1pLaY6IZ8yH",
      "metadata": {
        "id": "a1pLaY6IZ8yH",
        "outputId": "886aebe6-93bb-47fa-849e-0c6ae0554f06"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Token de Hugging Face cargado desde secretos de Colab.\n"
          ]
        }
      ],
      "source": [
        "from google.colab import userdata\n",
        "import os\n",
        "\n",
        "# Intenta obtener el token de Hugging Face del administrador de secretos\n",
        "HF_TOKEN = userdata.get('HF_TOKEN')\n",
        "\n",
        "# Opcional: Configura la variable de entorno HF_HOME si necesitas especificar una ubicación de caché diferente\n",
        "# os.environ['HF_HOME'] = '/content/drive/MyDrive/hf_cache'\n",
        "\n",
        "# Esto configurará el token para las bibliotecas de Hugging Face automáticamente\n",
        "if HF_TOKEN:\n",
        "    os.environ['HF_TOKEN'] = HF_TOKEN\n",
        "    print(\"Token de Hugging Face cargado desde secretos de Colab.\")\n",
        "else:\n",
        "    print(\"Advertencia: HF_TOKEN no encontrado en secretos de Colab.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5dpRhotUkmcO",
      "metadata": {
        "id": "5dpRhotUkmcO"
      },
      "source": [
        "Sólo actualizar en caso de que la carga del dataset de problemas:\n",
        "\n",
        "\"These are the names of the Python packages to be installed or upgraded. datasets is the Hugging Face library for easily accessing and working with datasets, and fsspec is a library that provides a file-system-like interface to various storage backends, which datasets uses internally.\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "zQuEUnFwhy6C",
      "metadata": {
        "id": "zQuEUnFwhy6C"
      },
      "outputs": [],
      "source": [
        "# !pip install --upgrade datasets fsspec"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0f7e7c7f",
      "metadata": {
        "id": "0f7e7c7f",
        "outputId": "7a4cb699-5578-4d3d-b734-68a41602a499",
        "colab": {
          "referenced_widgets": [
            "a79f20554f5c447a9c95a28988599f3c",
            "9dab70e8b66d40a1a1242c14961b745e",
            "c710aa748f364429b4c1b0ba6dbe3cb8",
            "24a5d9ac352d4f2ab8cffb758baeca15",
            "04b9fa3b9ba04198bd0ca6d6941aba15",
            "3f93ffc6854542d8910ed0a4374bbb53",
            "974f6accd92648cebdfe5e8989e4ff81"
          ]
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cargando el dataset IMDb completo...\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a79f20554f5c447a9c95a28988599f3c",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "README.md: 0.00B [00:00, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9dab70e8b66d40a1a1242c14961b745e",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "train-00000-of-00001.parquet:   0%|          | 0.00/21.0M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c710aa748f364429b4c1b0ba6dbe3cb8",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "test-00000-of-00001.parquet:   0%|          | 0.00/20.5M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "24a5d9ac352d4f2ab8cffb758baeca15",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "unsupervised-00000-of-00001.parquet:   0%|          | 0.00/42.0M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "04b9fa3b9ba04198bd0ca6d6941aba15",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Generating train split:   0%|          | 0/25000 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3f93ffc6854542d8910ed0a4374bbb53",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Generating test split:   0%|          | 0/25000 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "974f6accd92648cebdfe5e8989e4ff81",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Generating unsupervised split:   0%|          | 0/50000 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dataset IMDb cargado.\n"
          ]
        }
      ],
      "source": [
        "print(\"Cargando el dataset IMDb completo...\")\n",
        "dataset = load_dataset(\"imdb\")\n",
        "print(\"Dataset IMDb cargado.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b11441e5",
      "metadata": {
        "id": "b11441e5"
      },
      "outputs": [],
      "source": [
        "# Convertir a Pandas DataFrame y guardar como CSV\n",
        "df_train_original = pd.DataFrame(dataset[\"train\"])\n",
        "df_test_original = pd.DataFrame(dataset[\"test\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e98e681c",
      "metadata": {
        "id": "e98e681c"
      },
      "outputs": [],
      "source": [
        "train_csv_path = os.path.join(DRIVE_BASE_PATH, \"imdb_train_original.csv\")\n",
        "test_csv_path = os.path.join(DRIVE_BASE_PATH, \"imdb_test_original.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "530df172",
      "metadata": {
        "id": "530df172"
      },
      "outputs": [],
      "source": [
        "df_train_original.to_csv(train_csv_path, index=False)\n",
        "df_test_original.to_csv(test_csv_path, index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b5db00f1",
      "metadata": {
        "id": "b5db00f1",
        "outputId": "8427efc4-9c7e-43f1-c29b-8663727e54e2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dataset de entrenamiento original guardado en: /content/drive/My Drive/Colab Notebooks/mod03-projs/ai-small-language-model/imdb_train_original.csv\n",
            "Dataset de prueba original guardado en: /content/drive/My Drive/Colab Notebooks/mod03-projs/ai-small-language-model/imdb_test_original.csv\n",
            "Tamaño del dataset de entrenamiento original: 25000 registros\n",
            "Tamaño del dataset de prueba original: 25000 registros\n"
          ]
        }
      ],
      "source": [
        "print(f\"Dataset de entrenamiento original guardado en: {train_csv_path}\")\n",
        "print(f\"Dataset de prueba original guardado en: {test_csv_path}\")\n",
        "print(f\"Tamaño del dataset de entrenamiento original: {len(df_train_original)} registros\")\n",
        "print(f\"Tamaño del dataset de prueba original: {len(df_test_original)} registros\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5e83ce0d",
      "metadata": {
        "id": "5e83ce0d"
      },
      "source": [
        "## **Bloque 3: Unificación y Limpieza de Datos**"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "60cffaa9",
      "metadata": {
        "id": "60cffaa9"
      },
      "source": [
        "Este es el bloque crucial para la limpieza y unificación. Incluiré una función de limpieza básica y comprobaciones de\n",
        "nulos/duplicados."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ed8cd9af",
      "metadata": {
        "id": "ed8cd9af",
        "outputId": "8c8cc091-5f55-40f3-82a2-1365ec2321f8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Unificando datasets de entrenamiento y prueba...\n",
            "Dataset unificado creado con 50000 registros.\n"
          ]
        }
      ],
      "source": [
        "print(\"Unificando datasets de entrenamiento y prueba...\")\n",
        "df_full = pd.concat([df_train_original, df_test_original], ignore_index=True)\n",
        "print(f\"Dataset unificado creado con {len(df_full)} registros.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0b06a7fd",
      "metadata": {
        "id": "0b06a7fd",
        "outputId": "0119119f-09f2-43ed-fdb1-a7bd3695389a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Realizando comprobaciones de limpieza de datos...\n"
          ]
        }
      ],
      "source": [
        "print(\"Realizando comprobaciones de limpieza de datos...\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6d2fc6a3",
      "metadata": {
        "id": "6d2fc6a3",
        "outputId": "0bd4f04f-c960-47fc-ff2b-ce3915e5447c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Valores nulos por columna antes de la limpieza:\n",
            "text     0\n",
            "label    0\n",
            "dtype: int64\n"
          ]
        }
      ],
      "source": [
        "# Comprobar nulos\n",
        "print(f\"Valores nulos por columna antes de la limpieza:\\n{df_full.isnull().sum()}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "be79f2c0",
      "metadata": {
        "id": "be79f2c0",
        "outputId": "17cb0e7c-69b3-4043-b798-7d292248cf8d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Registros duplicados antes de la limpieza: 418\n",
            "Registros duplicados eliminados. Nuevo tamaño: 49582\n"
          ]
        }
      ],
      "source": [
        "# Comprobar duplicados\n",
        "print(f\"Registros duplicados antes de la limpieza: {df_full.duplicated().sum()}\")\n",
        "if df_full.duplicated().sum() > 0:\n",
        "    df_full.drop_duplicates(inplace=True)\n",
        "    print(f\"Registros duplicados eliminados. Nuevo tamaño: {len(df_full)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1c7330ac",
      "metadata": {
        "id": "1c7330ac"
      },
      "outputs": [],
      "source": [
        "# Función de limpieza de texto\n",
        "def clean_text(text):\n",
        "    text = str(text).lower() # Convertir a string y a minúsculas\n",
        "    text = re.sub(r'<br />', ' ', text) # Eliminar etiquetas <br />\n",
        "    text = re.sub(r'[^a-z0-9\\s]', '', text) # Eliminar caracteres especiales (mantener letras, números, espacios)\n",
        "    text = re.sub(r'\\s+', ' ', text).strip() # Eliminar espacios extra\n",
        "    return text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "aa5b28a2",
      "metadata": {
        "id": "aa5b28a2",
        "outputId": "24f44516-8016-427d-f7f5-839af5b599be"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Aplicando limpieza de texto a la columna 'text'...\n"
          ]
        }
      ],
      "source": [
        "print(\"Aplicando limpieza de texto a la columna 'text'...\")\n",
        "df_full['text'] = df_full['text'].apply(clean_text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a490ecbc",
      "metadata": {
        "id": "a490ecbc",
        "outputId": "5c7573ad-b023-4ba6-a3c4-75148fbe7df4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Registros con texto vacío después de la limpieza: 0\n"
          ]
        }
      ],
      "source": [
        "# Comprobar si hay \"nulos\" como cadenas vacías o solo espacios después de la limpieza\n",
        "print(f\"Registros con texto vacío después de la limpieza: {(df_full['text'] == '').sum()}\")\n",
        "if (df_full['text'] == '').sum() > 0:\n",
        "    df_full = df_full[df_full['text'] != '']\n",
        "    print(f\"Registros con texto vacío eliminados. Nuevo tamaño: {len(df_full)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5d84f5d9",
      "metadata": {
        "id": "5d84f5d9",
        "outputId": "082db062-88a4-4c65-c2c9-4316b6c6ebc8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dataset unificado y limpio guardado en: /content/drive/My Drive/Colab Notebooks/mod03-projs/ai-small-language-model/imdb_full_cleaned.csv\n"
          ]
        }
      ],
      "source": [
        "# Guardar el dataset unificado y limpio\n",
        "full_cleaned_csv_path = os.path.join(DRIVE_BASE_PATH, \"imdb_full_cleaned.csv\")\n",
        "df_full.to_csv(full_cleaned_csv_path, index=False)\n",
        "print(f\"Dataset unificado y limpio guardado en: {full_cleaned_csv_path}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "792042b4",
      "metadata": {
        "id": "792042b4"
      },
      "source": [
        "## **Bloque 4: División 80/20 para Entrenamiento y Prueba**"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5467ef3e",
      "metadata": {
        "id": "5467ef3e"
      },
      "source": [
        "Aquí dividiremos el dataset limpio en 80% para entrenamiento y 20% para prueba."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fe7fbf00",
      "metadata": {
        "id": "fe7fbf00",
        "outputId": "9f08011e-f8ae-4045-ddf1-f300c9f95b41"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dividiendo el dataset unificado en 80% entrenamiento y 20% prueba...\n"
          ]
        }
      ],
      "source": [
        "print(\"Dividiendo el dataset unificado en 80% entrenamiento y 20% prueba...\")\n",
        "train_df, test_df = train_test_split(df_full, test_size=0.2, random_state=42, stratify=df_full['label'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a3e8be62",
      "metadata": {
        "id": "a3e8be62"
      },
      "outputs": [],
      "source": [
        "# Convertir DataFrames de Pandas a objetos Dataset de Hugging Face\n",
        "train_dataset = Dataset.from_pandas(train_df)\n",
        "test_dataset = Dataset.from_pandas(test_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "23380d61",
      "metadata": {
        "id": "23380d61"
      },
      "outputs": [],
      "source": [
        "# Eliminar la columna '__index_level_0__' que se añade automáticamente al convertir de pandas\n",
        "train_dataset = train_dataset.remove_columns([\"__index_level_0__\"])\n",
        "test_dataset = test_dataset.remove_columns([\"__index_level_0__\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0dab6be7",
      "metadata": {
        "id": "0dab6be7",
        "outputId": "5e893109-ed2e-4f9a-af14-b16a86a2cc25"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Tamaño del dataset de entrenamiento (80%): 39665 registros\n",
            "Tamaño del dataset de prueba (20%): 9917 registros\n"
          ]
        }
      ],
      "source": [
        "print(f\"Tamaño del dataset de entrenamiento (80%): {len(train_dataset)} registros\")\n",
        "print(f\"Tamaño del dataset de prueba (20%): {len(test_dataset)} registros\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "117cc493",
      "metadata": {
        "id": "117cc493"
      },
      "source": [
        "## **Bloque 5: Tokenización y Carga del Modelo (Adaptado del Script Original)**"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "76c91103",
      "metadata": {
        "id": "76c91103"
      },
      "source": [
        "Este bloque es una adaptación directa del train_sentiment_model.py."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5b4810d0",
      "metadata": {
        "id": "5b4810d0",
        "outputId": "7949ca88-8d6b-4c4a-b54d-9e0178668605",
        "colab": {
          "referenced_widgets": [
            "98a05b820232468780d0b4a70b212f9c",
            "0f7fd69ca62a4b83bd03dc619c1bb5a6",
            "cb4cd443de6346ce9d5bdf332288b091",
            "31cb2525a1fa4b06b136b1ae894ea447"
          ]
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Cargando el tokenizador DistilBERT...\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "98a05b820232468780d0b4a70b212f9c",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0f7fd69ca62a4b83bd03dc619c1bb5a6",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "config.json:   0%|          | 0.00/483 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "cb4cd443de6346ce9d5bdf332288b091",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "31cb2525a1fa4b06b136b1ae894ea447",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Cargar el Tokenizador\n",
        "print(\"\\nCargando el tokenizador DistilBERT...\")\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-uncased\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2ec786b5",
      "metadata": {
        "id": "2ec786b5"
      },
      "outputs": [],
      "source": [
        "# Función de Preprocesamiento\n",
        "def preprocess_function(examples):\n",
        "    return tokenizer(examples[\"text\"], truncation=True, padding=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bedcfc83",
      "metadata": {
        "id": "bedcfc83",
        "outputId": "48d8a836-d82b-4879-8376-74a3c87215d6",
        "colab": {
          "referenced_widgets": [
            "713fd88b57fd41a48e6b3ecd6109bfbd",
            "bf1bfdc8961f406aaa6f8d29855fbb2a"
          ]
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Preprocesando el dataset de entrenamiento y prueba...\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "713fd88b57fd41a48e6b3ecd6109bfbd",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/39665 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "bf1bfdc8961f406aaa6f8d29855fbb2a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/9917 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "print(\"\\nPreprocesando el dataset de entrenamiento y prueba...\")\n",
        "tokenized_train_dataset = train_dataset.map(preprocess_function, batched=True)\n",
        "tokenized_test_dataset = test_dataset.map(preprocess_function, batched=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ef234c21",
      "metadata": {
        "id": "ef234c21",
        "outputId": "69d667d5-9351-4b43-bfb8-15e41417e639",
        "colab": {
          "referenced_widgets": [
            "65b5a414d2a540b5aca4360c1279b3cc"
          ]
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Cargando el modelo DistilBERT para clasificación de secuencias...\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "65b5a414d2a540b5aca4360c1279b3cc",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/268M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ],
      "source": [
        "# Cargar el Modelo\n",
        "print(\"\\nCargando el modelo DistilBERT para clasificación de secuencias...\")\n",
        "model = AutoModelForSequenceClassification.from_pretrained(\"distilbert-base-uncased\", num_labels=2)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "15681754",
      "metadata": {
        "id": "15681754"
      },
      "source": [
        "## **Bloque 6: Definición de Métricas y Configuración de Entrenamiento**"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "82995b4f",
      "metadata": {
        "id": "82995b4f"
      },
      "source": [
        "También adaptado de tu script original."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ca182114",
      "metadata": {
        "id": "ca182114",
        "outputId": "4cfa46a4-6422-4556-d831-1579f8876c92",
        "colab": {
          "referenced_widgets": [
            "ece3a5e1d2dc40bfb01106a5df2a0590",
            "1f251d2380ac484e8ced1c9098c76722",
            "c11a1fe55ca14b01ae1708627ab15eff",
            "e5884357b3f24632946525a68da9ce31"
          ]
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Definiendo métricas de evaluación...\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ece3a5e1d2dc40bfb01106a5df2a0590",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading builder script: 0.00B [00:00, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1f251d2380ac484e8ced1c9098c76722",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading builder script: 0.00B [00:00, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c11a1fe55ca14b01ae1708627ab15eff",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading builder script: 0.00B [00:00, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e5884357b3f24632946525a68da9ce31",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading builder script: 0.00B [00:00, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Definir Métricas de Evaluación\n",
        "print(\"\\nDefiniendo métricas de evaluación...\")\n",
        "metric = load(\"accuracy\")\n",
        "f1_metric = load(\"f1\")\n",
        "precision_metric = load(\"precision\")\n",
        "recall_metric = load(\"recall\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2262caac",
      "metadata": {
        "id": "2262caac"
      },
      "outputs": [],
      "source": [
        "def compute_metrics(eval_pred):\n",
        "    logits, labels = eval_pred\n",
        "    predictions = np.argmax(logits, axis=-1)\n",
        "    accuracy = metric.compute(predictions=predictions, references=labels)\n",
        "    f1 = f1_metric.compute(predictions=predictions, references=labels, average=\"weighted\")\n",
        "    precision = precision_metric.compute(predictions=predictions, references=labels, average=\"weighted\")\n",
        "    recall = recall_metric.compute(predictions=predictions, references=labels, average=\"weighted\")\n",
        "    return {**accuracy, **f1, **precision, **recall}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e65TCzLa2Rks",
      "metadata": {
        "id": "e65TCzLa2Rks",
        "outputId": "4702e3da-a86c-4277-ae86-a24d34bc1052"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "La versión de Transformers que se está usando es: 4.54.0\n"
          ]
        }
      ],
      "source": [
        "import transformers\n",
        "print(f\"La versión de Transformers que se está usando es: {transformers.__version__}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0c9f4d05",
      "metadata": {
        "id": "0c9f4d05",
        "outputId": "9bf5a2f8-6838-4038-c80c-2eef4b2c6149"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\nprint(\"\\nConfigurando argumentos de entrenamiento...\")\\ntraining_args = TrainingArguments(\\n    output_dir=os.path.join(DRIVE_BASE_PATH, \"results\"), # Directorio para guardar los resultados en Drive\\n    num_train_epochs=3,                   # Número de épocas de entrenamiento\\n    per_device_train_batch_size=16,  # Tamaño del batch por dispositivo (GPU/CPU)\\n    per_device_eval_batch_size=16,   # Tamaño del batch para evaluación\\n    warmup_steps=500,                   # Número de pasos para el calentamiento del learning rate\\n    weight_decay=0.01,                  # Regularización L2\\n    logging_dir=os.path.join(DRIVE_BASE_PATH, \"logs\"), # Directorio para los logs de TensorBoard en Drive\\n    logging_steps=100,\\n    report_to=\"none\",                   # No reportar a ninguna plataforma (ej. wandb)\\n    save_strategy=\"epoch\",            # Guardar el modelo al final de cada época\\n    evaluation_strategy=\"epoch\",      # <<-- Añadido: Evaluar al final de cada época para que load_best_model_at_end funcione\\n    load_best_model_at_end=True,     # Cargar el mejor modelo al final del entrenamiento\\n    metric_for_best_model=\"f1\",      # Métrica para determinar el mejor modelo\\n)\\n'"
            ]
          },
          "execution_count": 40,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Configurar Argumentos de Entrenamiento\n",
        "\"\"\"\n",
        "print(\"\\nConfigurando argumentos de entrenamiento...\")\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=os.path.join(DRIVE_BASE_PATH, \"results\"), # Directorio para guardar los resultados en Drive\n",
        "    num_train_epochs=3,                   # Número de épocas de entrenamiento\n",
        "    per_device_train_batch_size=16,  # Tamaño del batch por dispositivo (GPU/CPU)\n",
        "    per_device_eval_batch_size=16,   # Tamaño del batch para evaluación\n",
        "    warmup_steps=500,                   # Número de pasos para el calentamiento del learning rate\n",
        "    weight_decay=0.01,                  # Regularización L2\n",
        "    logging_dir=os.path.join(DRIVE_BASE_PATH, \"logs\"), # Directorio para los logs de TensorBoard en Drive\n",
        "    logging_steps=100,\n",
        "    report_to=\"none\",                   # No reportar a ninguna plataforma (ej. wandb)\n",
        "    save_strategy=\"epoch\",            # Guardar el modelo al final de cada época\n",
        "    evaluation_strategy=\"epoch\",      # <<-- Añadido: Evaluar al final de cada época para que load_best_model_at_end funcione\n",
        "    load_best_model_at_end=True,     # Cargar el mejor modelo al final del entrenamiento\n",
        "    metric_for_best_model=\"f1\",      # Métrica para determinar el mejor modelo\n",
        ")\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c0628c3c",
      "metadata": {
        "id": "c0628c3c"
      },
      "source": [
        "## **Bloque 7: Entrenamiento del Modelo**"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "G2zOohrkGA5f",
      "metadata": {
        "id": "G2zOohrkGA5f"
      },
      "source": [
        "import os\n",
        "import numpy as np\n",
        "# Importaciones necesarias para las métricas\n",
        "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
        "# Importaciones de Hugging Face Transformers y Datasets\n",
        "# Estas deberían estar ya en tu entorno Colab o haber sido instaladas previamente.\n",
        "# Asumo que `Trainer`, `TrainingArguments`, `AutoModelForSequenceClassification`\n",
        "# y `tokenized_datasets` (que contiene \"train\" y \"test\" datasets) están disponibles\n",
        "# del contexto del notebook previo.\n",
        "from transformers import Trainer, TrainingArguments, AutoModelForSequenceClassification\n",
        "\n",
        "# ==============================================================================\n",
        "# 1. FUNCIÓN PARA CALCULAR MÉTRICAS\n",
        "# El Trainer necesita una función que le diga CÓMO calcular las métricas\n",
        "# en el conjunto de evaluación durante el entrenamiento. Definimos esta función\n",
        "# para que reporte las métricas clave para problemas de clasificación binaria:\n",
        "# 'f1' (F1-score), 'precision', 'recall' y 'accuracy' (exactitud).\n",
        "# ==============================================================================\n",
        "def compute_metrics(pred):\n",
        "    \"\"\"\n",
        "    Calcula y devuelve un diccionario de métricas de evaluación a partir de las predicciones del modelo.\n",
        "\n",
        "    Args:\n",
        "        pred (EvalPrediction): Un objeto que contiene los logits (predicciones crudas)\n",
        "                               y las etiquetas verdaderas del conjunto de evaluación.\n",
        "\n",
        "    Returns:\n",
        "        dict: Un diccionario con las métricas calculadas (accuracy, f1, precision, recall).\n",
        "    \"\"\"\n",
        "    # `pred.label_ids` contiene las etiquetas verdaderas del conjunto de evaluación.\n",
        "    labels = pred.label_ids\n",
        "    # `pred.predictions` contiene los logits (salidas crudas del modelo antes de la activación final).\n",
        "    # `np.argmax(pred.predictions, axis=1)` convierte estos logits en las clases predichas\n",
        "    # (0 o 1 para clasificación binaria) seleccionando el índice de la mayor probabilidad.\n",
        "    preds = np.argmax(pred.predictions, axis=1)\n",
        "\n",
        "    # `precision_recall_fscore_support` calcula la precisión, el recall y el F1-score.\n",
        "    # `average='binary'` es crucial para problemas de clasificación binaria, donde se calcula\n",
        "    # para la clase positiva (generalmente 1).\n",
        "    precision, recall, f1, _ = precision_recall_fscore_support(labels, preds, average='binary')\n",
        "    # `accuracy_score` calcula la proporción de predicciones correctas.\n",
        "    acc = accuracy_score(labels, preds)\n",
        "\n",
        "    # Se devuelve un diccionario con todas las métricas calculadas. El Trainer usará esto\n",
        "    # para registrar el progreso de la evaluación.\n",
        "    return {\n",
        "        'accuracy': acc,\n",
        "        'f1': f1,\n",
        "        'precision': precision,\n",
        "        'recall': recall\n",
        "    }\n",
        "\n",
        "# ==============================================================================\n",
        "# 2. CONFIGURAR ARGUMENTOS DE ENTRENAMIENTO (TrainingArguments)\n",
        "# Esta sección define los parámetros y estrategias para el proceso de entrenamiento.\n",
        "# Usaremos `eval_steps` y `save_steps` para evaluar y guardar checkpoints\n",
        "# de manera periódica, específicamente al final de cada época completa.\n",
        "# ==============================================================================\n",
        "print(\"\\nConfigurando argumentos de entrenamiento...\")\n",
        "\n",
        "# Calculamos cuántos pasos de entrenamiento hay en una época.\n",
        "# Este cálculo es crucial para la estrategia de evaluación y guardado.\n",
        "# Si el dataset IMDb tiene 25,000 ejemplos de entrenamiento y el tamaño del batch es 16,\n",
        "# entonces los pasos por época serán 25000 / 16. Usamos la división entera (`//`)\n",
        "# para obtener un número de pasos completo.\n",
        "# Este valor (`steps_per_epoch`) se usará para configurar `eval_steps` y `save_steps`.\n",
        "# Esto significa que el modelo se evaluará y se guardará un checkpoint *cada vez*\n",
        "# que se haya procesado el dataset de entrenamiento completo una vez.\n",
        "steps_per_epoch = 25000 // 16 # Asumiendo 25,000 ejemplos de entrenamiento en el dataset IMDb.\n",
        "\n",
        "# Se instancia la clase `TrainingArguments` con los parámetros deseados.\n",
        "training_args = TrainingArguments(\n",
        "    # --- ¡AQUÍ ESTÁ EL CAMBIO CLAVE! ---\n",
        "    # Usamos os.path.join para construir la ruta completa dentro de tu Drive.\n",
        "    output_dir=os.path.join(DRIVE_BASE_PATH, \"results\"), # Guardará los checkpoints en Drive, # Directorio donde el Trainer guardará los checkpoints del modelo,\n",
        "                            # los logs y otros resultados del entrenamiento.\n",
        "    num_train_epochs=3,     # Número total de épocas (pasos completos sobre el dataset de entrenamiento)\n",
        "                            # para realizar el entrenamiento.\n",
        "    per_device_train_batch_size=16, # Tamaño del batch de datos por dispositivo (GPU/CPU) para el entrenamiento.\n",
        "                                    # Un tamaño de batch adecuado puede optimizar el uso de memoria y la velocidad.\n",
        "    per_device_eval_batch_size=16,  # Tamaño del batch de datos por dispositivo para la evaluación.\n",
        "                                    # Puede ser diferente al tamaño del batch de entrenamiento.\n",
        "    warmup_steps=500,       # Número de pasos para el \"calentamiento\" del learning rate. Durante estos pasos,\n",
        "                            # el learning rate aumenta gradualmente desde 0 hasta el valor inicial,\n",
        "                            # lo que puede ayudar a estabilizar el entrenamiento.\n",
        "    weight_decay=0.01,      # Factor de regularización L2 (descomposición de peso). Ayuda a prevenir el sobreajuste\n",
        "                            # penalizando los pesos grandes del modelo.\n",
        "    logging_dir=os.path.join(DRIVE_BASE_PATH, \"logs\"), # Guardará los logs de TensorBoard en Drive   # Directorio donde se guardarán los logs de TensorBoard para visualizar el progreso del entrenamiento.\n",
        "    logging_steps=100,      # Frecuencia (en pasos de entrenamiento) con la que se registrarán las métricas y el progreso.\n",
        "    report_to=\"none\",       # Deshabilita la integración con herramientas de reporte externas como Weights & Biases (wandb).\n",
        "                            # Puedes cambiar esto si deseas integrar con alguna de ellas.\n",
        "\n",
        "    # --- ¡AQUÍ ESTÁ LA CLAVE PARA LA EVALUACIÓN Y GUARDADO PERIÓDICO! ---\n",
        "    # `eval_steps`: Frecuencia (en pasos de entrenamiento) con la que se realizará una evaluación\n",
        "    # en el `eval_dataset`. Al establecerlo a `steps_per_epoch`, evaluamos al final de cada época.\n",
        "    eval_steps=steps_per_epoch,\n",
        "\n",
        "    # `save_steps`: Frecuencia (en pasos de entrenamiento) con la que se guardará un checkpoint\n",
        "    # del modelo. Al establecerlo a `steps_per_epoch`, guardamos un checkpoint al final de cada época.\n",
        "    save_steps=steps_per_epoch,\n",
        "\n",
        "    # IMPORTANTE: `load_best_model_at_end` no se puede usar con `eval_steps` y `save_steps`\n",
        "    # de esta manera en algunas versiones de `Trainer` (o si se requiere una lógica de selección\n",
        "    # de modelo más específica). Por eso, se realizará la carga del mejor modelo manualmente\n",
        "    # después del entrenamiento, basándonos en los resultados de evaluación registrados.\n",
        "    # load_best_model_at_end=True, # Deshabilitado o comentado por la estrategia manual\n",
        "    # metric_for_best_model=\"f1\",  # Deshabilitado o comentado por la estrategia manual\n",
        ")\n",
        "\n",
        "# ==============================================================================\n",
        "# 3. CREAR Y ENTRENAR EL TRAINER\n",
        "# Esta sección instancia el `Trainer` con el modelo, los argumentos de entrenamiento,\n",
        "# y los conjuntos de datos, y luego inicia el proceso de entrenamiento.\n",
        "# ==============================================================================\n",
        "print(\"\\nCreando el Trainer...\")\n",
        "# Se crea el objeto `Trainer`, que encapsula toda la lógica de entrenamiento.\n",
        "trainer = Trainer(\n",
        "    model=model,  # El modelo de Transformers (ej. DistilBERT) a entrenar.\n",
        "    args=training_args,  # Los argumentos de entrenamiento definidos en la sección anterior.\n",
        "    # Conjunto de datos de entrenamiento. Asegúrate de que `tokenized_datasets`\n",
        "    # esté definido y contenga las claves \"train\" y \"test\" (o los nombres que uses para tus splits).\n",
        "    train_dataset=tokenized_train_dataset,\n",
        "    # Conjunto de datos de evaluación. Este dataset se usará para medir el rendimiento del modelo\n",
        "    # en datos no vistos durante el entrenamiento, según la frecuencia definida por `eval_steps`.\n",
        "    eval_dataset=tokenized_test_dataset,\n",
        "    # Se especifica la función `compute_metrics` que se utilizará para calcular y reportar\n",
        "    # las métricas durante las evaluaciones periódicas.\n",
        "    compute_metrics=compute_metrics,\n",
        "    # Se pasa el tokenizador al Trainer. Esto es una buena práctica ya que el Trainer\n",
        "    # puede guardar el tokenizador junto con el modelo, facilitando la carga posterior\n",
        "    # del modelo entrenado con su tokenizador correspondiente.\n",
        "    tokenizer=tokenizer,\n",
        ")\n",
        "\n",
        "print(\"\\nIniciando el entrenamiento del modelo...\")\n",
        "# Inicia el ciclo de entrenamiento. El `Trainer` gestionará las épocas, los pasos,\n",
        "# las evaluaciones y el guardado de checkpoints según los `training_args`.\n",
        "trainer.train()\n",
        "print(\"\\nEntrenamiento completado.\")\n",
        "\n",
        "\n",
        "# ==============================================================================\n",
        "# 4. ENCONTRAR Y CARGAR EL MEJOR MODELO MANUALMENTE\n",
        "# Dado que `load_best_model_at_end` no se usó (o no era compatible con la estrategia\n",
        "# de evaluación/guardado deseada), necesitamos inspeccionar el historial de entrenamiento\n",
        "# para identificar el checkpoint que produjo el mejor rendimiento (basado en 'f1')\n",
        "# y luego cargar ese modelo específico.\n",
        "# ==============================================================================\n",
        "print(\"\\nBuscando el mejor checkpoint según la métrica 'f1'...\")\n",
        "\n",
        "# Inicializamos las variables para rastrear el F1-score más alto encontrado\n",
        "# y la ruta al directorio de ese checkpoint.\n",
        "best_metric = -1          # Se inicializa con un valor muy bajo para asegurar que la primera métrica real sea mejor.\n",
        "best_checkpoint_dir = None # Se inicializa a None; se actualizará con la ruta del mejor checkpoint.\n",
        "\n",
        "# El historial completo de logs de entrenamiento y evaluación está disponible\n",
        "# en `trainer.state.log_history`. Este es una lista de diccionarios, donde cada diccionario\n",
        "# representa un evento de log (ej., progreso del entrenamiento, resultados de evaluación).\n",
        "for log in trainer.state.log_history:\n",
        "    # Filtramos las entradas del log que corresponden a una evaluación, identificadas\n",
        "    # por la presencia de la clave 'eval_f1' (o cualquier otra métrica de evaluación).\n",
        "    if 'eval_f1' in log:\n",
        "        # Comprobamos si el F1-score de la evaluación actual es superior al mejor F1-score\n",
        "        # registrado hasta el momento.\n",
        "        if log['eval_f1'] > best_metric:\n",
        "            # Si es así, actualizamos `best_metric` con el nuevo valor.\n",
        "            best_metric = log['eval_f1']\n",
        "            # Extraemos el número de paso ('step') en el que se realizó esta evaluación.\n",
        "            # Los checkpoints se guardan en directorios nombrados como `checkpoint-<step>`.\n",
        "            step = log['step']\n",
        "            # Construimos la ruta completa al directorio del mejor checkpoint utilizando\n",
        "            # `training_args.output_dir` (el directorio base de resultados) y el número de paso.\n",
        "            best_checkpoint_dir = os.path.join(training_args.output_dir, f\"checkpoint-{step}\")\n",
        "\n",
        "# Después de revisar todo el historial, si `best_checkpoint_dir` no es None y existe físicamente,\n",
        "# significa que se encontró un mejor checkpoint.\n",
        "if best_checkpoint_dir and os.path.exists(best_checkpoint_dir):\n",
        "    # Imprimimos la ruta del mejor checkpoint y su correspondiente F1-score.\n",
        "    print(f\"El mejor checkpoint es: {best_checkpoint_dir} con un F1-score de: {best_metric:.4f}\")\n",
        "    print(\"\\nCargando el mejor modelo...\")\n",
        "    # Cargamos el modelo (sus pesos y configuración) desde el directorio del mejor checkpoint.\n",
        "    # `AutoModelForSequenceClassification.from_pretrained()` es la forma estándar de hacer esto\n",
        "    # para modelos de Transformers.\n",
        "    best_model = AutoModelForSequenceClassification.from_pretrained(best_checkpoint_dir)\n",
        "    print(\"¡Mejor modelo cargado y listo para usar!\")\n",
        "\n",
        "    # ==============================================================================\n",
        "    # 5. EVALUACIÓN FINAL DEL MEJOR MODELO CARGADO\n",
        "    # Una vez que el mejor modelo ha sido identificado y cargado, es una buena práctica\n",
        "    # realizar una evaluación final explícita en el conjunto de prueba para confirmar\n",
        "    # su rendimiento. Esto es especialmente útil si `load_best_model_at_end` no se usó.\n",
        "    # ==============================================================================\n",
        "    print(\"\\nEvaluando el MEJOR modelo en el conjunto de prueba...\")\n",
        "    # Para la evaluación final, podemos crear un nuevo `Trainer` usando el `best_model`\n",
        "    # que acabamos de cargar. Esto asegura que la evaluación se realice con el modelo óptimo.\n",
        "    final_trainer = Trainer(model=best_model, # El modelo que hemos identificado como el mejor.\n",
        "                            args=training_args, # Reutilizamos los argumentos de entrenamiento, ya que contienen\n",
        "                                                # la configuración de evaluación (ej. batch size).\n",
        "                            eval_dataset=tokenized_test_dataset, # El conjunto de datos de prueba para la evaluación final.\n",
        "                            compute_metrics=compute_metrics) # La función de métricas para calcular los resultados.\n",
        "    # Ejecutamos el método `evaluate()` del `final_trainer` para obtener las métricas\n",
        "    # de rendimiento del mejor modelo en el conjunto de prueba.\n",
        "    eval_results = final_trainer.evaluate()\n",
        "    # Imprimimos los resultados de la evaluación final del mejor modelo.\n",
        "    print(f\"\\nResultados de la evaluación del MEJOR modelo: {eval_results}\")\n",
        "\n",
        "else:\n",
        "    # Si `best_checkpoint_dir` es `None` o el directorio no existe (lo cual sería inusual si el entrenamiento\n",
        "    # ocurrió correctamente y se generaron logs de evaluación), significa que no se pudo identificar\n",
        "    # un \"mejor\" checkpoint basándose en las métricas registradas. En este caso, se asume que\n",
        "    # el modelo final que `trainer.train()` dejó es el que se debe evaluar.\n",
        "    print(\"\\nNo se encontraron checkpoints de evaluación con métricas válidas. Evaluando el último modelo entrenado.\")\n",
        "    # Se evalúa el modelo tal como quedó al finalizar el entrenamiento (`trainer.model`).\n",
        "    # Aunque no sea el \"mejor\" según la métrica F1, es el resultado del entrenamiento completo.\n",
        "    eval_results = trainer.evaluate()\n",
        "    # La variable `best_model` apuntará al último estado del modelo entrenado.\n",
        "    best_model = trainer.model\n",
        "    print(f\"Resultados de la evaluación final (último modelo): {eval_results}\")\n",
        "\n",
        "# A partir de este punto, la variable `best_model` contendrá el modelo de Transformer\n",
        "# que se identificó como el mejor durante el entrenamiento (o el último entrenado si\n",
        "# no se encontraron mejores checkpoints), listo para ser utilizado en tareas de inferencia\n",
        "# (predicción de sentimiento para nuevas reseñas)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dbv0b6GICUH5",
      "metadata": {
        "id": "dbv0b6GICUH5",
        "outputId": "f5e0162e-7912-49e9-bb41-3e0eba6c09e7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Configurando argumentos de entrenamiento...\n",
            "\n",
            "Creando el Trainer...\n",
            "\n",
            "Iniciando el entrenamiento del modelo...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-41-742057063.py:150: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
            "  trainer = Trainer(\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='257' max='7440' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [ 257/7440 3:20:57 < 94:20:54, 0.02 it/s, Epoch 0.10/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>100</td>\n",
              "      <td>0.668800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>0.390200</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-41-742057063.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    174\u001b[0m \u001b[0;31m# se evaluará periódicamente en el conjunto de evaluación y guardará checkpoints\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m \u001b[0;31m# según la estrategia definida en `training_args`.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 176\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    177\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\nEntrenamiento completado.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   2235\u001b[0m                 \u001b[0mhf_hub_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menable_progress_bars\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2236\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2237\u001b[0;31m             return inner_training_loop(\n\u001b[0m\u001b[1;32m   2238\u001b[0m                 \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2239\u001b[0m                 \u001b[0mresume_from_checkpoint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mresume_from_checkpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36m_inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   2576\u001b[0m                     )\n\u001b[1;32m   2577\u001b[0m                     \u001b[0;32mwith\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2578\u001b[0;31m                         \u001b[0mtr_loss_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_items_in_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2579\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2580\u001b[0m                     if (\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mtraining_step\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m   3838\u001b[0m                 \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"scale_wrt_gas\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3839\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3840\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maccelerator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3841\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3842\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/accelerate/accelerator.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, loss, **kwargs)\u001b[0m\n\u001b[1;32m   2576\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlomo_backward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2577\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2578\u001b[0;31m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2579\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2580\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mset_trigger\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    624\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    625\u001b[0m             )\n\u001b[0;32m--> 626\u001b[0;31m         torch.autograd.backward(\n\u001b[0m\u001b[1;32m    627\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    628\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    345\u001b[0m     \u001b[0;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    346\u001b[0m     \u001b[0;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 347\u001b[0;31m     _engine_run_backward(\n\u001b[0m\u001b[1;32m    348\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    349\u001b[0m         \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\u001b[0m in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    821\u001b[0m         \u001b[0munregister_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_register_logging_hooks_on_whole_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    822\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 823\u001b[0;31m         return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    824\u001b[0m             \u001b[0mt_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    825\u001b[0m         )  # Calls into the C++ engine to run the backward pass\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "# Importaciones necesarias para las métricas\n",
        "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
        "# Importaciones de Hugging Face Transformers y Datasets\n",
        "# Estas librerías son fundamentales para trabajar con modelos pre-entrenados como DistilBERT\n",
        "# y para gestionar el proceso de entrenamiento de forma eficiente.\n",
        "# Se asume que `model` (tu modelo DistilBERT cargado), `tokenizer` (su tokenizador),\n",
        "# `tokenized_train_dataset` y `tokenized_test_dataset` (tus datos ya procesados)\n",
        "# están definidos en celdas anteriores de tu notebook.\n",
        "from transformers import Trainer, TrainingArguments, AutoModelForSequenceClassification\n",
        "\n",
        "# ==============================================================================\n",
        "# 1. FUNCIÓN PARA CALCULAR MÉTRICAS\n",
        "# El `Trainer` de Hugging Face necesita una función personalizada que le indique\n",
        "# cómo calcular las métricas de rendimiento del modelo en el conjunto de evaluación\n",
        "# durante el entrenamiento. Esta función se invocará periódicamente para\n",
        "# monitorear el progreso del modelo.\n",
        "# Para un problema de clasificación de sentimiento binario (positivo/negativo),\n",
        "# las métricas clave son 'f1' (F1-score), 'precision', 'recall' y 'accuracy' (exactitud).\n",
        "# ==============================================================================\n",
        "def compute_metrics(pred):\n",
        "    \"\"\"\n",
        "    Calcula y devuelve un diccionario de métricas de evaluación a partir de las predicciones del modelo.\n",
        "    Esta función es crucial para monitorear el rendimiento del modelo durante el entrenamiento\n",
        "    y para la evaluación final.\n",
        "\n",
        "    Args:\n",
        "        pred (EvalPrediction): Un objeto `EvalPrediction` proporcionado por el `Trainer`.\n",
        "                               Contiene:\n",
        "                               - `pred.predictions`: Los logits (salidas crudas del modelo antes de la activación final)\n",
        "                                 para cada ejemplo del conjunto de evaluación.\n",
        "                               - `pred.label_ids`: Las etiquetas verdaderas (ground truth)\n",
        "                                 correspondientes a los ejemplos de evaluación.\n",
        "\n",
        "    Returns:\n",
        "        dict: Un diccionario donde las claves son los nombres de las métricas (ej., 'accuracy', 'f1')\n",
        "              y los valores son sus respectivos resultados calculados.\n",
        "    \"\"\"\n",
        "    # Extraemos las etiquetas verdaderas del objeto de predicción.\n",
        "    labels = pred.label_ids\n",
        "    # Convertimos los logits del modelo en predicciones de clase.\n",
        "    # `np.argmax(pred.predictions, axis=1)` toma el índice de la probabilidad más alta\n",
        "    # a lo largo del eje de las clases (axis=1) para determinar la clase predicha (0 o 1).\n",
        "    preds = np.argmax(pred.predictions, axis=1)\n",
        "\n",
        "    # Calculamos la precisión, el recall y el F1-score.\n",
        "    # `average='binary'` es fundamental para problemas de clasificación binaria,\n",
        "    # ya que calcula estas métricas específicamente para la clase positiva (generalmente 1).\n",
        "    precision, recall, f1, _ = precision_recall_fscore_support(labels, preds, average='binary')\n",
        "    # Calculamos la exactitud (accuracy), que es la proporción de predicciones correctas.\n",
        "    acc = accuracy_score(labels, preds)\n",
        "\n",
        "    # Devolvemos un diccionario con todas las métricas calculadas.\n",
        "    # El `Trainer` utilizará estos valores para registrar el progreso de la evaluación\n",
        "    # y para decidir qué checkpoint es el \"mejor\".\n",
        "    return {\n",
        "        'accuracy': acc,\n",
        "        'f1': f1,\n",
        "        'precision': precision,\n",
        "        'recall': recall\n",
        "    }\n",
        "\n",
        "# ==============================================================================\n",
        "# 2. CONFIGURAR ARGUMENTOS DE ENTRENAMIENTO (TrainingArguments)\n",
        "# Esta sección es donde definimos todos los hiperparámetros y estrategias\n",
        "# que guiarán el proceso de entrenamiento del modelo. Esto incluye dónde guardar\n",
        "# los resultados, cuántas veces iterar sobre los datos, el tamaño de los lotes,\n",
        "# y la frecuencia de evaluación y guardado de checkpoints.\n",
        "# ==============================================================================\n",
        "print(\"\\nConfigurando argumentos de entrenamiento...\")\n",
        "\n",
        "# Calculamos el número de pasos de entrenamiento por época.\n",
        "# Un \"paso\" (step) es una actualización de los pesos del modelo después de procesar un batch de datos.\n",
        "# Una \"época\" (epoch) es una pasada completa por todo el conjunto de datos de entrenamiento.\n",
        "# Para el dataset IMDb con 25,000 ejemplos de entrenamiento y un tamaño de batch de 16,\n",
        "# los pasos por época se calculan como: 25000 / 16.\n",
        "# Usamos la división entera (`//`) para obtener un número de pasos completo.\n",
        "# Este valor (`steps_per_epoch`) se utilizará para configurar la frecuencia de evaluación\n",
        "# y de guardado de checkpoints, asegurando que se realice al final de cada época.\n",
        "steps_per_epoch = 25000 // 16 # Asumiendo 25,000 ejemplos de entrenamiento en el dataset IMDb.\n",
        "\n",
        "# Se instancia la clase `TrainingArguments` con los parámetros deseados para el entrenamiento.\n",
        "training_args = TrainingArguments(\n",
        "    # --- ¡CAMBIO CLAVE PARA GUARDAR EN GOOGLE DRIVE! ---\n",
        "    # `output_dir`: Directorio donde el `Trainer` guardará todos los resultados del entrenamiento,\n",
        "    # incluyendo los checkpoints del modelo (copias del modelo en diferentes puntos del entrenamiento),\n",
        "    # los logs y el modelo final.\n",
        "    # Usamos `os.path.join(DRIVE_BASE_PATH, \"results\")` para asegurar que todo se guarde\n",
        "    # directamente en tu Google Drive, dentro de una carpeta \"results\" en la ruta base.\n",
        "    output_dir=os.path.join(DRIVE_BASE_PATH, \"results\"),\n",
        "    num_train_epochs=3,     # Número total de épocas para entrenar el modelo.\n",
        "                            # El modelo iterará sobre todo el `train_dataset` 3 veces.\n",
        "    per_device_train_batch_size=16, # Tamaño del lote de datos por dispositivo (GPU/CPU) durante el entrenamiento.\n",
        "                                    # Un tamaño de batch adecuado es crucial para el rendimiento y el uso de memoria.\n",
        "    per_device_eval_batch_size=16,  # Tamaño del lote de datos por dispositivo durante la evaluación.\n",
        "                                    # Puede ser diferente al tamaño del batch de entrenamiento.\n",
        "    warmup_steps=500,       # Número de pasos de \"calentamiento\" para el learning rate.\n",
        "                            # Durante estos pasos iniciales, el learning rate aumenta gradualmente,\n",
        "                            # lo que puede ayudar a estabilizar el entrenamiento en sus primeras etapas.\n",
        "    weight_decay=0.01,      # Factor de regularización L2 (también conocido como \"descomposición de peso\").\n",
        "                            # Ayuda a prevenir el sobreajuste (overfitting) penalizando los pesos grandes del modelo,\n",
        "                            # lo que fomenta modelos más simples y generalizables.\n",
        "    # --- ¡CAMBIO CLAVE PARA GUARDAR LOGS EN GOOGLE DRIVE! ---\n",
        "    # `logging_dir`: Directorio donde se guardarán los logs de TensorBoard.\n",
        "    # Estos logs son útiles para visualizar el progreso del entrenamiento (pérdida, métricas)\n",
        "    # a lo largo del tiempo utilizando TensorBoard.\n",
        "    # También se guarda en Google Drive para persistencia.\n",
        "    logging_dir=os.path.join(DRIVE_BASE_PATH, \"logs\"),\n",
        "    logging_steps=100,      # Frecuencia (en pasos de entrenamiento) con la que se registrarán\n",
        "                            # las métricas de entrenamiento en los logs.\n",
        "    report_to=\"none\",       # Deshabilita la integración con herramientas de reporte externas\n",
        "                            # como Weights & Biases (wandb) o MLflow. Si deseas usarlas,\n",
        "                            # puedes cambiar este valor (ej., \"wandb\").\n",
        "\n",
        "    # --- ¡ESTRATEGIAS DE EVALUACIÓN Y GUARDADO DE CHECKPOINTS! ---\n",
        "    # `eval_steps`: Frecuencia (en pasos de entrenamiento) con la que el `Trainer`\n",
        "    # realizará una evaluación en el `eval_dataset`. Al establecerlo a `steps_per_epoch`,\n",
        "    # nos aseguramos de que el modelo se evalúe al final de cada época completa.\n",
        "    eval_steps=steps_per_epoch,\n",
        "\n",
        "    # `save_steps`: Frecuencia (en pasos de entrenamiento) con la que se guardará un\n",
        "    # \"checkpoint\" (una copia del estado actual del modelo y del optimizador).\n",
        "    # Al establecerlo a `steps_per_epoch`, se guarda un checkpoint al final de cada época.\n",
        "    # Esto es crucial para la recuperación en caso de interrupciones o para seleccionar\n",
        "    # el mejor modelo después del entrenamiento.\n",
        "    save_steps=steps_per_epoch,\n",
        "\n",
        "    # Nota importante sobre `load_best_model_at_end`:\n",
        "    # En esta configuración, hemos decidido manejar la carga del \"mejor modelo\" manualmente\n",
        "    # después de que el entrenamiento ha finalizado. Esto nos da más control y es compatible\n",
        "    # con la estrategia de `eval_steps` y `save_steps` que hemos definido.\n",
        "    # Si `load_best_model_at_end=True` estuviera habilitado, el `Trainer` cargaría\n",
        "    # automáticamente el mejor modelo al final del entrenamiento basándose en la métrica\n",
        "    # especificada por `metric_for_best_model`. Sin embargo, para esta implementación\n",
        "    # manual, lo mantenemos deshabilitado.\n",
        "    # load_best_model_at_end=True, # Deshabilitado para la estrategia manual de selección.\n",
        "    # metric_for_best_model=\"f1\",  # Deshabilitado para la estrategia manual de selección.\n",
        ")\n",
        "\n",
        "# ==============================================================================\n",
        "# 3. CREAR Y ENTRENAR EL TRAINER\n",
        "# En esta fase, instanciamos el objeto `Trainer` con todos los componentes\n",
        "# necesarios (el modelo, los argumentos de entrenamiento, los datasets y\n",
        "# la función de métricas) y luego iniciamos el proceso de entrenamiento.\n",
        "# ==============================================================================\n",
        "print(\"\\nCreando el Trainer...\")\n",
        "# Se crea el objeto `Trainer`, que es la clase central de Hugging Face para\n",
        "# orquestar el entrenamiento y la evaluación de modelos de Transformers.\n",
        "trainer = Trainer(\n",
        "    model=model,  # El modelo de Transformers (ej. DistilBERT) que se va a entrenar.\n",
        "    args=training_args,  # Los argumentos de entrenamiento que definimos en la sección anterior.\n",
        "    # Conjunto de datos de entrenamiento.\n",
        "    # `tokenized_train_dataset` debe ser un objeto `Dataset` (o similar)\n",
        "    # que contenga los datos de entrenamiento ya preprocesados y tokenizados.\n",
        "    train_dataset=tokenized_train_dataset,\n",
        "    # Conjunto de datos de evaluación.\n",
        "    # `tokenized_test_dataset` se utilizará para evaluar el rendimiento del modelo\n",
        "    # en datos no vistos durante el entrenamiento, según la frecuencia definida por `eval_steps`.\n",
        "    eval_dataset=tokenized_test_dataset,\n",
        "    # Se especifica la función `compute_metrics` que se utilizará para calcular y reportar\n",
        "    # las métricas de evaluación (accuracy, f1, precision, recall) periódicamente.\n",
        "    compute_metrics=compute_metrics,\n",
        "    # Se pasa el tokenizador al `Trainer`. Esto es una buena práctica ya que permite\n",
        "    # al `Trainer` guardar el tokenizador junto con el modelo, lo que es crucial\n",
        "    # para la reproducibilidad y para cargar correctamente el modelo entrenado\n",
        "    # para inferencia posterior.\n",
        "    tokenizer=tokenizer,\n",
        ")\n",
        "\n",
        "print(\"\\nIniciando el entrenamiento del modelo...\")\n",
        "# Llama al método `train()` del objeto `Trainer` para iniciar el ciclo de entrenamiento.\n",
        "# Durante este proceso, el modelo aprenderá de los datos de entrenamiento,\n",
        "# se evaluará periódicamente en el conjunto de evaluación y guardará checkpoints\n",
        "# según la estrategia definida en `training_args`.\n",
        "trainer.train()\n",
        "print(\"\\nEntrenamiento completado.\")\n",
        "\n",
        "\n",
        "# ==============================================================================\n",
        "# 4. ENCONTRAR Y CARGAR EL MEJOR MODELO MANUALMENTE\n",
        "# Dado que no utilizamos `load_best_model_at_end=True` en `TrainingArguments`,\n",
        "# necesitamos examinar el historial de entrenamiento para identificar el checkpoint\n",
        "# que logró el mejor rendimiento (basado en el F1-score) y luego cargar ese modelo.\n",
        "# Esto asegura que estamos seleccionando la versión más óptima del modelo.\n",
        "# ==============================================================================\n",
        "print(\"\\nBuscando el mejor checkpoint según la métrica 'f1'...\")\n",
        "\n",
        "# Inicializamos las variables para rastrear el F1-score más alto encontrado\n",
        "# y la ruta al directorio de ese checkpoint.\n",
        "best_metric = -1          # Se inicializa con un valor muy bajo para que cualquier F1-score real sea mayor.\n",
        "best_checkpoint_dir = None # Se inicializa a None; se actualizará con la ruta del mejor checkpoint.\n",
        "\n",
        "# El historial completo de logs de entrenamiento y evaluación se almacena\n",
        "# en `trainer.state.log_history`. Este es una lista de diccionarios, donde cada\n",
        "# diccionario representa un evento de log (ej., el progreso del entrenamiento,\n",
        "# o los resultados de una evaluación).\n",
        "for log in trainer.state.log_history:\n",
        "    # Filtramos las entradas del log que corresponden a una evaluación.\n",
        "    # Las entradas de evaluación contienen métricas como 'eval_f1'.\n",
        "    if 'eval_f1' in log:\n",
        "        # Comprobamos si el F1-score de la evaluación actual es superior\n",
        "        # al mejor F1-score registrado hasta el momento.\n",
        "        if log['eval_f1'] > best_metric:\n",
        "            # Si es así, actualizamos `best_metric` con el nuevo valor.\n",
        "            best_metric = log['eval_f1']\n",
        "            # Extraemos el número de paso ('step') en el que se realizó esta evaluación.\n",
        "            # Los checkpoints se guardan en subdirectorios con el formato 'checkpoint-<step>'.\n",
        "            step = log['step']\n",
        "            # Construimos la ruta completa al directorio de este mejor checkpoint.\n",
        "            # Utilizamos `training_args.output_dir` (que ahora apunta a tu Drive)\n",
        "            # y el número de paso para formar la ruta completa.\n",
        "            best_checkpoint_dir = os.path.join(training_args.output_dir, f\"checkpoint-{step}\")\n",
        "\n",
        "# Después de revisar todo el historial, si `best_checkpoint_dir` no es None\n",
        "# y el directorio existe físicamente, significa que se encontró un mejor checkpoint.\n",
        "if best_checkpoint_dir and os.path.exists(best_checkpoint_dir):\n",
        "    # Imprimimos la información del mejor checkpoint encontrado.\n",
        "    print(f\"El mejor checkpoint es: {best_checkpoint_dir} con un F1-score de: {best_metric:.4f}\")\n",
        "    print(\"\\nCargando el mejor modelo...\")\n",
        "    # Cargamos el modelo (sus pesos y configuración) desde el directorio del mejor checkpoint.\n",
        "    # `AutoModelForSequenceClassification.from_pretrained()` es la forma estándar de hacer esto\n",
        "    # para modelos de Transformers, cargando el modelo que obtuvo las mejores métricas.\n",
        "    best_model = AutoModelForSequenceClassification.from_pretrained(best_checkpoint_dir)\n",
        "    print(\"¡Mejor modelo cargado y listo para usar!\")\n",
        "\n",
        "    # ==============================================================================\n",
        "    # 5. EVALUACIÓN FINAL DEL MEJOR MODELO CARGADO\n",
        "    # Una vez que el mejor modelo ha sido identificado y cargado, es una buena práctica\n",
        "    # realizar una evaluación final explícita en el conjunto de prueba para confirmar\n",
        "    # su rendimiento. Esto es especialmente útil si `load_best_model_at_end` no fue\n",
        "    # configurado o si se quiere una evaluación explícita del modelo cargado.\n",
        "    # ==============================================================================\n",
        "    print(\"\\nEvaluando el MEJOR modelo en el conjunto de prueba...\")\n",
        "    # Para la evaluación final, creamos un nuevo objeto `Trainer` que utilizará\n",
        "    # el `best_model` que acabamos de cargar. Esto asegura que la evaluación\n",
        "    # se realice con la versión más óptima del modelo.\n",
        "    final_trainer = Trainer(model=best_model, # El modelo que hemos identificado como el mejor.\n",
        "                            args=training_args, # Reutilizamos los mismos argumentos de entrenamiento\n",
        "                                                # (necesarios para la configuración de la evaluación,\n",
        "                                                # como el tamaño del batch de evaluación).\n",
        "                            eval_dataset=tokenized_test_dataset, # El conjunto de datos de prueba para la evaluación final.\n",
        "                            compute_metrics=compute_metrics) # La función de métricas para calcular los resultados.\n",
        "    # Ejecutamos el método `evaluate()` del `final_trainer` para obtener las métricas\n",
        "    # de rendimiento del mejor modelo en el conjunto de prueba.\n",
        "    eval_results = final_trainer.evaluate()\n",
        "    # Imprimimos los resultados de la evaluación final del mejor modelo.\n",
        "    print(f\"\\nResultados de la evaluación del MEJOR modelo: {eval_results}\")\n",
        "\n",
        "else:\n",
        "    # Si por alguna razón no se encontró ningún checkpoint de evaluación con métricas válidas\n",
        "    # (lo cual sería inusual si el entrenamiento fue exitoso y se generaron logs de evaluación),\n",
        "    # o si el directorio del mejor checkpoint no existe, se evaluará el último modelo entrenado\n",
        "    # que el `trainer` original dejó.\n",
        "    print(\"\\nNo se encontraron checkpoints de evaluación con métricas válidas. Evaluando el último modelo entrenado.\")\n",
        "    # Se evalúa el modelo tal como quedó al finalizar `trainer.train()`.\n",
        "    eval_results = trainer.evaluate() # Se evalúa el modelo actual del `trainer`.\n",
        "    # En este caso, la variable `best_model` apuntará al último estado del modelo entrenado.\n",
        "    best_model = trainer.model\n",
        "    print(f\"Resultados de la evaluación final (último modelo): {eval_results}\")\n",
        "\n",
        "# A partir de este punto, la variable `best_model` contendrá el modelo de Transformer\n",
        "# que se identificó como el mejor durante el entrenamiento (o el último entrenado si\n",
        "# no se encontraron mejores checkpoints), listo para ser utilizado para inferencia\n",
        "# (predicción de sentimiento para nuevas reseñas).\n",
        "\n",
        "# ==============================================================================\n",
        "# 6. GUARDAR EL MODELO ENTRENADO Y EL TOKENIZADOR EN GOOGLE DRIVE\n",
        "# Una vez que el entrenamiento ha finalizado y hemos identificado el mejor modelo,\n",
        "# es crucial guardarlo junto con su tokenizador. Esto permite reutilizar el modelo\n",
        "# en el futuro sin necesidad de reentrenarlo y asegura que el tokenizador\n",
        "# utilizado para el preprocesamiento de los datos de inferencia sea el mismo\n",
        "# que se usó durante el entrenamiento.\n",
        "# ==============================================================================\n",
        "\n",
        "# Definimos la ruta completa en Google Drive donde se guardará el modelo.\n",
        "# Usamos el nombre de carpeta `fine_tuned_sentiment_model_full_data` como solicitaste.\n",
        "model_save_path_drive = os.path.join(DRIVE_BASE_PATH, \"fine_tuned_sentiment_model_full_data\")\n",
        "print(f\"\\nGuardando el modelo y tokenizador en Google Drive: {model_save_path_drive}\")\n",
        "\n",
        "# Guardamos el `best_model` (el modelo con las mejores métricas) y su `tokenizer`.\n",
        "# `save_pretrained()` guarda la configuración del modelo, los pesos (pytorch_model.bin o model.safetensors)\n",
        "# y los archivos del tokenizador (tokenizer_config.json, vocab.txt, special_tokens_map.json, etc.)\n",
        "# en el directorio especificado.\n",
        "best_model.save_pretrained(model_save_path_drive)\n",
        "tokenizer.save_pretrained(model_save_path_drive)\n",
        "print(\"Modelo y tokenizador guardados exitosamente en Google Drive.\")\n",
        "\n",
        "# ==============================================================================\n",
        "# 7. VERIFICAR TAMAÑO Y DIVIDIR EL ARCHIVO DEL MODELO PARA SUBIR A GITHUB (OPCIONAL)\n",
        "# GitHub tiene un límite de tamaño de archivo de 100MB. Los modelos grandes\n",
        "# pueden exceder este límite. Esta sección verifica el tamaño del archivo principal\n",
        "# del modelo y lo divide en partes más pequeñas si es necesario, facilitando su subida.\n",
        "# ==============================================================================\n",
        "\n",
        "# Primero, intentamos encontrar el archivo principal de los pesos del modelo.\n",
        "# Los modelos de PyTorch suelen guardarse como `pytorch_model.bin`.\n",
        "# Los modelos más nuevos o guardados con `safetensors` pueden ser `model.safetensors`.\n",
        "model_bin_path = os.path.join(model_save_path_drive, \"pytorch_model.bin\")\n",
        "# Si no se encuentra `pytorch_model.bin`, intentamos con `model.safetensors`.\n",
        "if not os.path.exists(model_bin_path):\n",
        "    model_bin_path = os.path.join(model_save_path_drive, \"model.safetensors\")\n",
        "\n",
        "# Verificamos si se encontró el archivo principal del modelo antes de proceder.\n",
        "if os.path.exists(model_bin_path):\n",
        "    # Obtenemos el tamaño del archivo en bytes y lo convertimos a Megabytes (MB).\n",
        "    file_size_mb = os.path.getsize(model_bin_path) / (1024 * 1024)\n",
        "    print(f\"\\nTamaño del archivo del modelo ({os.path.basename(model_bin_path)}): {file_size_mb:.2f} MB\")\n",
        "\n",
        "    # Definimos el umbral de tamaño para la división (90MB para estar seguros por debajo de 100MB de GitHub).\n",
        "    if file_size_mb > 90:\n",
        "        print(f\"El archivo del modelo ({os.path.basename(model_bin_path)}) excede los 90MB. Dividiendo...\")\n",
        "\n",
        "        # Función auxiliar para dividir un archivo grande en partes más pequeñas.\n",
        "        def split_file(filepath, chunk_size_mb=90):\n",
        "            \"\"\"\n",
        "            Divide un archivo grande en múltiples partes más pequeñas.\n",
        "\n",
        "            Args:\n",
        "                filepath (str): La ruta completa del archivo a dividir.\n",
        "                chunk_size_mb (int): El tamaño máximo deseado para cada parte en Megabytes.\n",
        "            \"\"\"\n",
        "            # Convertimos el tamaño del chunk de MB a bytes.\n",
        "            chunk_size = int(chunk_size_mb * 1024 * 1024)\n",
        "            # Extraemos el nombre base del archivo y el directorio de salida.\n",
        "            base_filename = os.path.basename(filepath)\n",
        "            output_dir = os.path.dirname(filepath)\n",
        "\n",
        "            # Abrimos el archivo original en modo binario de lectura.\n",
        "            with open(filepath, 'rb') as f:\n",
        "                part_num = 0 # Contador para el número de parte.\n",
        "                while True:\n",
        "                    # Leemos un chunk del archivo.\n",
        "                    chunk = f.read(chunk_size)\n",
        "                    # Si no hay más datos, hemos terminado.\n",
        "                    if not chunk:\n",
        "                        break\n",
        "                    # Construimos el nombre del archivo de la parte (ej., pytorch_model.bin.part000).\n",
        "                    part_filename = os.path.join(output_dir, f\"{base_filename}.part{part_num:03d}\")\n",
        "                    # Escribimos el chunk en el archivo de la parte.\n",
        "                    with open(part_filename, 'wb') as part_f:\n",
        "                        part_f.write(chunk)\n",
        "                    print(f\"  Creada parte: {os.path.basename(part_filename)}\")\n",
        "                    part_num += 1 # Incrementamos el contador de partes.\n",
        "            print(f\"Archivo '{base_filename}' dividido en {part_num} partes en {output_dir}.\")\n",
        "            print(\"Puedes subir estas partes a GitHub. Recuerda NO subir el archivo original grande.\")\n",
        "            print(\"Para reconstruir, puedes usar el comando 'cat' en sistemas Unix/Linux/macOS:\")\n",
        "            print(f\"  cat {base_filename}.part* > {base_filename}\")\n",
        "            print(\"O el comando 'copy /b' en Windows:\")\n",
        "            print(f\"  copy /b {base_filename}.part* {base_filename}\")\n",
        "            print(\"También puedes implementar una función 'join_files' en Python si lo necesitas.\")\n",
        "\n",
        "        # Llamamos a la función para dividir el archivo del modelo.\n",
        "        split_file(model_bin_path)\n",
        "    else:\n",
        "        print(\"El archivo del modelo es menor de 90MB. No es necesario dividirlo para GitHub.\")\n",
        "else:\n",
        "    # Mensaje de advertencia si no se encontró el archivo principal del modelo.\n",
        "    print(f\"Advertencia: No se encontró el archivo principal del modelo ({os.path.basename(model_bin_path)}).\")\n",
        "\n",
        "# ¡Tu modelo está ahora entrenado, evaluado, guardado en Drive y listo para ser gestionado!"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5ffa3529",
      "metadata": {
        "id": "5ffa3529"
      },
      "source": [
        "## **Bloque 8: Guardado del Modelo y División para GitHub**"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "05a33a6b",
      "metadata": {
        "id": "05a33a6b"
      },
      "source": [
        "Este bloque guardará el modelo en Google Drive y luego implementará la lógica para dividir el archivo pytorch_model.bin si es\n",
        "demasiado grande."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ca8bfa2a",
      "metadata": {
        "id": "ca8bfa2a"
      },
      "outputs": [],
      "source": [
        "# # 10. Guardar el Modelo en Google Drive\n",
        "# model_save_path_drive = os.path.join(DRIVE_BASE_PATH, \"fine_tuned_sentiment_model_full_data\")\n",
        "# print(f\"\\nGuardando el modelo y tokenizador en Google Drive: {model_save_path_drive}\")\n",
        "# trainer.save_model(model_save_path_drive)\n",
        "# tokenizer.save_pretrained(model_save_path_drive)\n",
        "# print(\"Modelo y tokenizador guardados exitosamente en Google Drive.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0c77c73a",
      "metadata": {
        "id": "0c77c73a"
      },
      "source": [
        "--- Lógica para dividir el modelo para GitHub ---\n",
        "GitHub tiene un límite de 100MB por archivo.\n",
        "El archivo principal del modelo suele ser 'pytorch_model.bin' o 'model.safetensors'."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e4d367c5",
      "metadata": {
        "id": "e4d367c5"
      },
      "outputs": [],
      "source": [
        "# model_bin_path = os.path.join(model_save_path_drive, \"pytorch_model.bin\")\n",
        "# if not os.path.exists(model_bin_path):\n",
        "#     # Si no es pytorch_model.bin, podría ser safetensors\n",
        "#     model_bin_path = os.path.join(model_save_path_drive, \"model.safetensors\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8a7586b0",
      "metadata": {
        "id": "8a7586b0"
      },
      "outputs": [],
      "source": [
        "# if os.path.exists(model_bin_path):\n",
        "#     file_size_mb = os.path.getsize(model_bin_path) / (1024 * 1024)\n",
        "#     print(f\"\\nTamaño del archivo del modelo ({os.path.basename(model_bin_path)}): {file_size_mb:.2f} MB\")\n",
        "\n",
        "#     if file_size_mb > 90: # Usamos 90MB como umbral para estar seguros por debajo de 100MB\n",
        "#         print(f\"El archivo del modelo ({os.path.basename(model_bin_path)}) excede los 90MB. Dividiendo...\")\n",
        "\n",
        "#         def split_file(filepath, chunk_size_mb=90):\n",
        "#             chunk_size = int(chunk_size_mb * 1024 * 1024)\n",
        "#             base_filename = os.path.basename(filepath)\n",
        "#             output_dir = os.path.dirname(filepath)\n",
        "\n",
        "#             with open(filepath, 'rb') as f:\n",
        "#                 part_num = 0\n",
        "#                 while True:\n",
        "#                     chunk = f.read(chunk_size)\n",
        "#                     if not chunk:\n",
        "#                         break\n",
        "#                     part_filename = os.path.join(output_dir, f\"{base_filename}.part{part_num:03d}\")\n",
        "#                     with open(part_filename, 'wb') as part_f:\n",
        "#                         part_f.write(chunk)\n",
        "#                     print(f\"  Creada parte: {os.path.basename(part_filename)}\")\n",
        "#                     part_num += 1\n",
        "#             print(f\"Archivo '{base_filename}' dividido en {part_num} partes en {output_dir}.\")\n",
        "#             print(\"Puedes subir estas partes a GitHub. Recuerda NO subir el archivo original grande.\")\n",
        "#             print(\"Para reconstruir, usa el comando 'cat' o la función 'join_files' proporcionada.\")\n",
        "\n",
        "#         split_file(model_bin_path)\n",
        "#     else:\n",
        "#         print(\"El archivo del modelo es menor de 90MB. No es necesario dividirlo para GitHub.\")\n",
        "# else:\n",
        "#     print(f\"Advertencia: No se encontró el archivo principal del modelo ({os.path.basename(model_bin_path)}).\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "25008b14",
      "metadata": {
        "id": "25008b14"
      },
      "source": [
        "Instrucciones para el Usuario"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "215d3987",
      "metadata": {
        "id": "215d3987",
        "lines_to_next_cell": 2
      },
      "source": [
        "1. Crea un nuevo Notebook en Google Colab:\n",
        "    * Ve a Google Colab (https://colab.research.google.com/).\n",
        "    * Haz clic en Archivo -> Nuevo notebook.\n",
        "2. Copia y Pega los Bloques de Código:\n",
        "    * Copia cada bloque de código que te he proporcionado y pégalo en celdas separadas en tu nuevo notebook.\n",
        "    * Ejecuta cada celda en orden.\n",
        "3. Asegúrate de que la carpeta `SLM_Training_Results` exista en tu Google Drive antes de ejecutar el notebook, o cámbiala a una\n",
        "ruta que prefieras.\n",
        "4. Conectar Colab con GitHub (para commits):\n",
        "    * Una vez que el entrenamiento haya terminado y tengas el notebook con los resultados, puedes guardarlo en GitHub.\n",
        "    * Ve a Archivo -> Guardar una copia en GitHub....\n",
        "    * Sigue las instrucciones para autorizar Colab y seleccionar tu repositorio.\n",
        "    * Para los archivos del modelo divididos, tendrás que descargarlos de Google Drive a tu máquina local y luego subirlos\n",
        "    manualmente a GitHub (o usar git directamente en Colab si clonas tu repositorio y trabajas dentro de él, lo cual es más\n",
        "    avanzado)."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2ee2f956",
      "metadata": {
        "id": "2ee2f956"
      },
      "source": [
        "Función para Reconstruir el Modelo (para uso local)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "52448e3e",
      "metadata": {
        "id": "52448e3e"
      },
      "source": [
        "Si necesitas reconstruir el modelo a partir de las partes descargadas de GitHub en tu máquina local, usa esta función Python:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "331afa2b",
      "metadata": {
        "id": "331afa2b"
      },
      "outputs": [],
      "source": [
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7894958e",
      "metadata": {
        "id": "7894958e"
      },
      "outputs": [],
      "source": [
        "# def join_files(output_filepath, part_prefix):\n",
        "#     \"\"\"\n",
        "#     Reconstruye un archivo a partir de sus partes.\n",
        "#     output_filepath: Ruta completa del archivo final a reconstruir.\n",
        "#     part_prefix: Prefijo de los archivos de las partes (ej.\n",
        "#     \"./fine_tuned_sentiment_model_full_data/pytorch_model.bin.part\").\n",
        "#                  Asegúrate de que incluya la ruta completa a las partes.\n",
        "#     \"\"\"\n",
        "#     print(f\"Reconstruyendo archivo en: {output_filepath}\")\n",
        "#     with open(output_filepath, 'wb') as outfile:\n",
        "#         part_num = 0\n",
        "#         while True:\n",
        "#             # Formato de nombre de parte: .part000, .part001, etc.\n",
        "#             part_filename = f\"{part_prefix}{part_num:03d}\"\n",
        "#             if not os.path.exists(part_filename):\n",
        "#                 break\n",
        "#             print(f\"  Añadiendo parte: {os.path.basename(part_filename)}\")\n",
        "#             with open(part_filename, 'rb') as infile:\n",
        "#                 outfile.write(infile.read())\n",
        "#             part_num += 1\n",
        "#     if part_num > 0:\n",
        "#         print(f\"Archivo reconstruido exitosamente en '{output_filepath}' a partir de {part_num} partes.\")\n",
        "#     else:\n",
        "#         print(f\"Advertencia: No se encontraron partes con el prefijo '{part_prefix}'.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f44943b1",
      "metadata": {
        "id": "f44943b1"
      },
      "source": [
        "Ejemplo de uso (ajusta las rutas según donde descargues las partes):\n",
        "\n",
        "- model_dir = \"./fine_tuned_sentiment_model_full_data\" # Carpeta donde están las partes\n",
        "- output_file = os.path.join(model_dir, \"pytorch_model.bin\")\n",
        "- part_base_name = \"pytorch_model.bin.part\" # Nombre base del archivo original\n",
        "- join_files(output_file, os.path.join(model_dir, part_base_name))"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}